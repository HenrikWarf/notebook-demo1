{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "differential-disclosure",
   "metadata": {},
   "source": [
    "# Composer Pipeline running ML in BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "roman-synthesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "biological-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = 'bqml-logistic-regression.py'\n",
    "DAG_FOLDER = 'gs://us-east1-compose-crazy-a3d52ae3-bucket/dags/'\n",
    "\n",
    "os.environ['FILE_NAME'] = FILE_NAME\n",
    "os.environ['DAG_FOLDER'] = DAG_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-poland",
   "metadata": {},
   "source": [
    "#### Saving composer python file to local storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "experienced-veteran",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting bqml-logistic-regression.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {FILE_NAME}\n",
    "\n",
    "import datetime\n",
    "import logging\n",
    "from airflow import DAG\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "from google.cloud import bigquery\n",
    "from airflow.contrib.operators import bigquery_operator\n",
    "\n",
    "dag = DAG(\n",
    "        'Earnings_ml_model_log_regression',\n",
    "        schedule_interval='@weekly',\n",
    "        start_date=datetime.datetime.now()\n",
    ")\n",
    "\n",
    "def read_raw_storage():\n",
    "    client = bigquery.Client()\n",
    "    dataset_id = 'machine_learning_02'\n",
    "    dataset_ref = client.dataset(dataset_id)\n",
    "\n",
    "    #Job Configuration Parameters\n",
    "    job_config = bigquery.LoadJobConfig()\n",
    "    job_config.autodetect = True\n",
    "    job_config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "    job_config.source_format = bigquery.SourceFormat.CSV\n",
    "    data_uri = \"gs://crazy-hippo-01/dataset/census_train.csv\"\n",
    "\n",
    "    load_job = client.load_table_from_uri(data_uri, dataset_ref.table(\"income_model\"), job_config=job_config)\n",
    "                                            \n",
    "    logging.info(\"Starting job {}\".format(load_job.job_id))\n",
    "\n",
    "    results = load_job.result()  # Waits for table load to complete.\n",
    "    logging.info(\"Job finished.\")\n",
    "\n",
    "    destination_table = client.get_table(\"machine_learning_02.income_model\")\n",
    "    logging.info(\"Loaded {} rows.\".format(destination_table.num_rows))                                      \n",
    "\n",
    "read_raw_storage = PythonOperator(\n",
    "    task_id=\"read_raw_storage\",\n",
    "    python_callable=read_raw_storage,\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "bq_clean_table = bigquery_operator.BigQueryOperator(\n",
    "    task_id='bq_clean_table',\n",
    "    bql=\"\"\"\n",
    "    SELECT age, workclass, gender, occupation, education_num, marital_status, relationship, capital_gain, income_bracket\n",
    "    FROM `crazy-hippo-01.machine_learning_02.income_model` \n",
    "    WHERE workclass IS NOT NULL AND workclass != \"Never-worked\"\n",
    "    \"\"\",\n",
    "    use_legacy_sql=False,\n",
    "    destination_dataset_table=\"machine_learning_02.bq_clean_table\",\n",
    "    write_disposition=\"WRITE_TRUNCATE\",\n",
    "    location=\"US\"\n",
    ")\n",
    "\n",
    "model_training = bigquery_operator.BigQueryOperator(\n",
    "    task_id='model_training',\n",
    "    bql=\"\"\"\n",
    "    CREATE OR REPLACE MODEL machine_learning_02.income_model_log_classifier\n",
    "    OPTIONS(input_label_cols=['income_bracket'], model_type='logistic_reg')\n",
    "    AS \n",
    "    SELECT *\n",
    "    FROM `crazy-hippo-01.machine_learning_02.bq_clean_table`\n",
    "    \"\"\",\n",
    "    use_legacy_sql=False,\n",
    "    write_disposition=\"WRITE_TRUNCATE\",\n",
    "    location=\"US\"\n",
    ")\n",
    "\n",
    "model_evaluation = bigquery_operator.BigQueryOperator(\n",
    "    task_id='model_evaluation',\n",
    "    bql=\"\"\"\n",
    "    INSERT machine_learning_02.evaluation_log_regression (Accuracy, f1_Score, Precision, Recall, ROC_AUC) \n",
    "    SELECT ROUND(precision,2) as Accuracy, ROUND(recall,2) as f1_Score, ROUND(accuracy,2) as Precision, ROUND(f1_score,2) as Recall, ROUND(roc_auc,2) as ROC_AUC\n",
    "    FROM\n",
    "    ML.EVALUATE(MODEL `machine_learning_02.income_model_log_classifier`)\n",
    "    \"\"\",\n",
    "    use_legacy_sql=False,\n",
    "    write_disposition=\"WRITE_TRUNCATE\",\n",
    "    location=\"US\"\n",
    ")\n",
    "\n",
    "\n",
    "# Configure Task Dependencies\n",
    "read_raw_storage >> bq_clean_table\n",
    "bq_clean_table >> model_training\n",
    "model_training >> model_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-portrait",
   "metadata": {},
   "source": [
    "#### Copy new file to DAG folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "strange-planner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bqml-logistic-regression.py does not exist. Copying file to DAG folder....\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://bqml-logistic-regression.py [Content-Type=text/x-python]...\n",
      "/ [1 files][  2.9 KiB/  2.9 KiB]                                                \n",
      "Operation completed over 1 objects/2.9 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "#Check if Model already exists\n",
    "if [[ $(gsutil ls $DAG_FOLDER | grep $FILE_NAME) ]]; then\n",
    "    echo \"$FILE already exists\"\n",
    "else\n",
    "    # create model\n",
    "    echo \"$FILE_NAME does not exist. Copying file to DAG folder....\"\n",
    "    gsutil cp $FILE_NAME $DAG_FOLDER\n",
    "    echo \"Done!\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-river",
   "metadata": {},
   "source": [
    "#### Update file already in DAG folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "champion-logan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " already exists\n",
      "bqml-logistic-regression.py  Copying file to DAG folder....\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://us-east1-compose-crazy-a3d52ae3-bucket/dags/bqml-logistic-regression.py...\n",
      "/ [1 objects]                                                                   \n",
      "Operation completed over 1 objects.                                              \n",
      "Copying file://bqml-logistic-regression.py [Content-Type=text/x-python]...\n",
      "/ [1 files][  3.0 KiB/  3.0 KiB]                                                \n",
      "Operation completed over 1 objects/3.0 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "#Check if Model already exists\n",
    "if [[ $(gsutil ls $DAG_FOLDER | grep $FILE_NAME) ]]; then\n",
    "    echo \"$FILE already exists\"\n",
    "    # delete file\n",
    "    gsutil del $DAG_FOLDER$FILE_NAME\n",
    "    # copy file\n",
    "    echo \"$FILE_NAME  Copying file to DAG folder....\"\n",
    "    gsutil cp $FILE_NAME gs://us-east1-compose-crazy-a3d52ae3-bucket/dags/\n",
    "    echo \"Done!\"\n",
    "else\n",
    "    # File Exists\n",
    "    echo \"$FILE_NAME does not exist...\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-absorption",
   "metadata": {},
   "source": [
    "#### Delete file in DAG folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-saskatchewan",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil del $DAG_FOLDER$FILE_NAME"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.mnightly-2021-01-20-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:mnightly-2021-01-20-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
