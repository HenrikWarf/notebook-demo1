{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "quality-teddy",
   "metadata": {},
   "source": [
    "# Create & Deploy Vertex-AI Pipeline w/ Kubeflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-charge",
   "metadata": {},
   "source": [
    "Install the needed libraries in order to run the code locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lucky-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install google-cloud-aiplatform==1.0.0 --upgrade\n",
    "!pip3 install kfp google-cloud-pipeline-components==0.1.1 --upgrade\n",
    "!pip3 install scikit-learn\n",
    "!pip3 install google-cloud-aiplatform --upgrade\n",
    "!pip3 install pandas\n",
    "!pip3 install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-personal",
   "metadata": {},
   "source": [
    "Might need to restart kernel after initial installation of the cell above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "protecting-plymouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from kfp import dsl\n",
    "import kfp\n",
    "from google.cloud import aiplatform\n",
    "from kfp.v2.dsl import component\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output, OutputPath, component, Metrics)\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-evans",
   "metadata": {},
   "source": [
    "Getting some preset environment variables save to a local file. Create one of your own by following these instructions: https://stackoverflow.com/a/54028874"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "abstract-speech",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n",
      "kubeflow-demos\n",
      "user-group-demo\n",
      "gs://user-group-demo/pipeline_root\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/a/54028874\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "PROJECT_ID = os.environ['PROJECT_ID']\n",
    "BUCKET_NAME = os.environ['BUCKET']\n",
    "\n",
    "PIPELINE_ROOT = 'gs://{}/pipeline_root'.format(BUCKET_NAME)\n",
    "REGION = 'us-central1'\n",
    "\n",
    "print(PROJECT_ID)\n",
    "print(BUCKET_NAME)\n",
    "print(PIPELINE_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-server",
   "metadata": {},
   "source": [
    "## 1. Create a component for reading data from BQ into CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "talented-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(packages_to_install=[\"pandas\", \"google-cloud-aiplatform\", \"google-cloud-bigquery-storage\",\"google-cloud-bigquery\",\"pyarrow\"])\n",
    "def preprocess(output_csv_path: OutputPath('CSV')):\n",
    "    #1\n",
    "    from google.cloud import bigquery\n",
    "    import google.auth\n",
    "    \n",
    "    creds, project = google.auth.default()\n",
    "    client = bigquery.Client(project='kubeflow-demos', credentials=creds)\n",
    "\n",
    "    query =     \"\"\"\n",
    "            SELECT * FROM `kubeflow-demos.telco.churn`\n",
    "    \"\"\"\n",
    "    print(query)\n",
    "    \n",
    "    dataframe = client.query(query).to_dataframe()\n",
    "    print(dataframe.head())\n",
    "    \n",
    "    dataframe.to_csv(output_csv_path)\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-function",
   "metadata": {},
   "source": [
    "## 2. Create a component to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "internal-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(packages_to_install=[\"pandas\", \"imbalanced-learn\", \"google-cloud-aiplatform\", \"pyarrow\"])\n",
    "def train(input_csv_path: InputPath('CSV'), saved_model: Output[Model], artifact_uri: OutputPath(str), accuracy: Output[Metrics], model_type: str, project_id: str, bucket: str):\n",
    "    from google.cloud import aiplatform\n",
    "    from typing import NamedTuple\n",
    "    #Train\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(input_csv_path)\n",
    "    print(len(df))\n",
    "    \n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype=='object':    #Since we are encoding object datatype to integer/float\n",
    "            lbl = LabelEncoder()\n",
    "            lbl.fit(list(df[c].values))\n",
    "            df[c] = lbl.transform(df[c].values)\n",
    "    print(df.head())  #To check if properly encoded\n",
    "    \n",
    "    X = df[['Contract', 'tenure', 'TechSupport', 'OnlineSecurity', 'TotalCharges', 'PaperlessBilling',\n",
    "       'DeviceProtection', 'Dependents', 'OnlineBackup', 'SeniorCitizen', 'MonthlyCharges',\n",
    "       'PaymentMethod', 'Partner', 'PhoneService']] #taking only relevant columns\n",
    "    y = df['Churn']\n",
    "\n",
    "\n",
    "    # Scaling all the variables to a range of 0 to 1\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    features = X.columns.values\n",
    "    scaler = MinMaxScaler(feature_range = (0,1))\n",
    "    scaler.fit(X)\n",
    "    X = pd.DataFrame(scaler.transform(X))\n",
    "    X.columns = features\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "    #Choose which model to train\n",
    "    if model_type == 'linear_regression':\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        model = LogisticRegression()\n",
    "        \n",
    "    elif model_type == 'naive_bayes':\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "        model = GaussianNB()\n",
    "        \n",
    "    elif model_type == 'decision_tree':\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        model = DecisionTreeClassifier()\n",
    "        \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    #Save the model to disk and also automatically to GCS\n",
    "    import joblib\n",
    "    \n",
    "    joblib.dump(model, os.path.join(saved_model.path.replace(\"saved_model\",\"\"), 'model.joblib'))\n",
    "    print(\" saved_model.path: \"+ saved_model.path)\n",
    "    print(\" saved_model.uri: \"+ saved_model.uri)\n",
    "    with open(artifact_uri, 'w') as f:\n",
    "        f.write(saved_model.uri.replace(\"saved_model\",\"\"))\n",
    "    \n",
    "    print(saved_model.uri)\n",
    "    \n",
    "    accuracy = 7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-joint",
   "metadata": {},
   "source": [
    "## 3. Eval component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "checked-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component()\n",
    "def eval(baseline: float, accuracy: Input[Metrics]) -> bool:\n",
    "    isBetter = False\n",
    "    \n",
    "    print(str(dir(accuracy)))\n",
    "    new_val = float(Metrics.metadata[\"accuracy\"])\n",
    "    print(str(new_val))\n",
    "    \n",
    "    \n",
    "    if float(accuracy)>baseline:\n",
    "        isBetter = True\n",
    "    return isBetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "julian-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "better-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name=\"train-scikit\" + str(uuid.uuid4()))\n",
    "def pipeline(\n",
    "    project: str = PROJECT_ID,\n",
    "    bucket: str = BUCKET_NAME\n",
    "):\n",
    "    preprocess_task = preprocess()\n",
    "    \n",
    "    train_task = train(preprocess_task.output, model_type='linear_regression', project_id=PROJECT_ID, bucket=BUCKET_NAME)\n",
    "    #train_task2 = train(preprocess_task.output, model_type='naive_bayes', project_id=PROJECT_ID, bucket=BUCKET_NAME)\n",
    "    #train_task3 = train(preprocess_task.output, model_type='decision_tree', project_id=PROJECT_ID, bucket=BUCKET_NAME)\n",
    "    \n",
    "    eval_task = eval(5.3, train_task.outputs[\"accuracy\"])\n",
    "    \n",
    "    with dsl.Condition(eval_task.output==True, name=\"eval models\"):\n",
    "        model_upload_op = gcc_aip.ModelUploadOp(\n",
    "            project=PROJECT_ID,\n",
    "            display_name=\"model\"+TIMESTAMP, \n",
    "    #        artifact_uri=\"gs://user-group-demo/pipeline_root/141610882258/train-scikitf989f632-b955-4bb1-a72d-0480d1c08627-20210620145355/train_-6780204423378370560/\", # GCS location of model\n",
    "            artifact_uri=train_task.outputs[\"artifact_uri\"], # GCS location of model\n",
    "            serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-24:latest\",\n",
    "        )\n",
    "\n",
    "        endpoint_create_op = gcc_aip.EndpointCreateOp(\n",
    "            project=PROJECT_ID,\n",
    "            display_name=\"pipelines\"+TIMESTAMP,\n",
    "        )\n",
    "\n",
    "        model_deploy_op = gcc_aip.ModelDeployOp( \n",
    "            project=PROJECT_ID,\n",
    "            endpoint=endpoint_create_op.outputs[\"endpoint\"],\n",
    "            model=model_upload_op.outputs[\"model\"],\n",
    "            deployed_model_display_name=\"model_display_name\",\n",
    "            machine_type=\"n1-standard-4\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "designed-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2 import compiler\n",
    "\n",
    "compiler.Compiler().compile(pipeline_func=pipeline, \n",
    "                            package_path=\"dag-\"+TIMESTAMP+\".json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "english-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2.google.client import AIPlatformClient\n",
    "\n",
    "api_client = AIPlatformClient(\n",
    "    project_id=PROJECT_ID,\n",
    "    region=REGION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "rolled-pitch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/train-scikita525a9fc-1f1a-427c-aefa-f9128f1fe26c-20210702173421?project=kubeflow-demos\" target=\"_blank\" >here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = api_client.create_run_from_job_spec(\n",
    "    \"dag-\"+TIMESTAMP+\".json\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    parameter_values={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-roulette",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.mnightly-2021-01-20-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:mnightly-2021-01-20-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
