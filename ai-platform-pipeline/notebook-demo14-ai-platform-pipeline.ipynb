{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vocal-harvey",
   "metadata": {},
   "source": [
    "# AI Platform Pipeline with TFX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-latest",
   "metadata": {},
   "source": [
    "### Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bearing-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiplatform.pipelines import client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dirty-designation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://cloud-aiplatform-pipelines/releases/20210209/aiplatform_pipelines_client-0.1.0.caip20210209-py3-none-any.whl...\n",
      "/ [1 files][ 21.9 KiB/ 21.9 KiB]                                                \n",
      "Operation completed over 1 objects/21.9 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "# Get the AI Platform client library from restricted bucket\n",
    "!gsutil cp gs://cloud-aiplatform-pipelines/releases/20210209/aiplatform_pipelines_client-0.1.0.caip20210209-py3-none-any.whl .  \n",
    "# Get the Metadata SDK to query the produced metadata.\n",
    "!gsutil cp gs://cloud-aiplatform-metadata/sdk/google-cloud-aiplatform-metadata-0.0.1.tar.gz ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-dance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install both libraries\n",
    "!python3 -m pip install google-cloud-aiplatform\n",
    "!python3 -m pip install kfp==1.4 google-cloud-aiplatform-metadata-0.0.1.tar.gz aiplatform_pipelines_client-0.1.0.caip20210209-py3-none-any.whl --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "expressed-starter",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:RuntimeParameter is only supported on Cloud-based DAG runner currently.\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, Text, List\n",
    "import absl\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_analysis as tfma\n",
    "#from aiplatform.pipelines import client\n",
    "\n",
    "from tfx.components.example_gen.import_example_gen.component import ImportExampleGen\n",
    "from tfx.components import CsvExampleGen\n",
    "from tfx.components import Evaluator\n",
    "from tfx.components import ExampleValidator\n",
    "from tfx.components import InfraValidator\n",
    "from tfx.components import Pusher\n",
    "from tfx.components import ResolverNode\n",
    "from tfx.components import SchemaGen\n",
    "from tfx.components import StatisticsGen\n",
    "from tfx.components import Trainer\n",
    "from tfx.components import Transform\n",
    "from tfx.orchestration import metadata\n",
    "from ml_metadata.proto import metadata_store_pb2\n",
    "from tfx.components.trainer.executor import GenericExecutor\n",
    "from tfx.dsl.components.base import executor_spec\n",
    "from tfx.dsl.experimental import latest_artifacts_resolver ## demo\n",
    "from tfx.dsl.experimental import latest_blessed_model_resolver ## demo\n",
    "from tfx.orchestration import pipeline as tfx_pipeline\n",
    "from tfx.orchestration.local.local_dag_runner import LocalDagRunner\n",
    "from tfx.orchestration.kubeflow.v2 import kubeflow_v2_dag_runner\n",
    "from tfx.utils.dsl_utils import external_input\n",
    "from tfx.proto import example_gen_pb2\n",
    "from tfx.proto import pusher_pb2\n",
    "from tfx.proto import trainer_pb2\n",
    "from tfx.types import standard_artifacts\n",
    "from tfx.types import channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "parental-identity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.4.1\n",
      "TFX version: 0.27.0\n"
     ]
    }
   ],
   "source": [
    "# Check Versions of Pipeline\n",
    "print('TensorFlow version: {}'.format(tf.__version__))\n",
    "print('TFX version: {}'.format(__import__('tfx.version').__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-suffering",
   "metadata": {},
   "source": [
    "### Set Environment Variables for Local execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bulgarian-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID         = 'crazy-hippo-01'\n",
    "REGION             = 'us-central1'\n",
    "API_KEY            = ''\n",
    "PIPELINE_NAME      = 'earnings'\n",
    "PIPELINE_ROOT      = 'gs://crazy-hippo-01/tfx/binary_classification/pipeline'\n",
    "TRANSFORM_FILE     = 'transform.py'\n",
    "#TRANSFORM_FILE    = 'gs://crazy-hippo-01/tfx/binary_classification/transform.py'\n",
    "TRAINER_FILE       = 'trainer.py'\n",
    "#TRAINER_FILE      = 'gs://crazy-hippo-01/tfx/binary_classification/trainer.py'\n",
    "RAW_DATA           = \"gs://crazy-hippo-01/tfx/binary_classification/raw/\"\n",
    "SERVING_MODEL_DIR = 'gs://crazy-hippo-01/tfx/binary_classification/serving_model/'\n",
    "METADATA_PATH     = os.path.join('.', 'tfx_metadata', PIPELINE_NAME, 'metadata.db')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-antique",
   "metadata": {},
   "source": [
    "### Pipeline Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "permanent-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfx_pipeline(\n",
    "    pipeline_name: Text, input_dir: Text, metadata_connection_config: Optional[metadata_store_pb2.ConnectionConfig] = None\n",
    "    ):\n",
    "   \n",
    "    # Output 2 splits: train:eval=3:1.\n",
    "    example_gen = CsvExampleGen(input_base=RAW_DATA)\n",
    "    \n",
    "    statistics_gen = StatisticsGen(examples=example_gen.outputs['examples'])\n",
    "\n",
    "    schema_gen = SchemaGen(\n",
    "        statistics=statistics_gen.outputs['statistics'],\n",
    "        infer_feature_shape=True)\n",
    "\n",
    "    example_validator = ExampleValidator(\n",
    "        statistics=statistics_gen.outputs['statistics'],\n",
    "        schema=schema_gen.outputs['schema'])\n",
    "\n",
    "    transform = Transform(\n",
    "        examples=example_gen.outputs['examples'],\n",
    "        schema=schema_gen.outputs['schema'],\n",
    "        module_file=TRANSFORM_FILE)\n",
    "    \n",
    "    # Fetch the latest trained model under the same context for warm-starting.\n",
    "    latest_model_resolver = ResolverNode(\n",
    "        instance_name='latest_model_resolver',\n",
    "        resolver_class=latest_artifacts_resolver.LatestArtifactsResolver,\n",
    "        model=channel.Channel(type=standard_artifacts.Model))\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        module_file=TRAINER_FILE,\n",
    "        custom_executor_spec=executor_spec.ExecutorClassSpec(GenericExecutor),\n",
    "        examples=transform.outputs['transformed_examples'],\n",
    "        transform_graph=transform.outputs['transform_graph'],\n",
    "        schema=schema_gen.outputs['schema'],\n",
    "        train_args=trainer_pb2.TrainArgs(num_steps=3000),\n",
    "        eval_args=trainer_pb2.EvalArgs(num_steps=3000))\n",
    "    \n",
    "    # Get the latest blessed model for model validation.\n",
    "    model_resolver = ResolverNode(\n",
    "        instance_name='latest_blessed_model_resolver',\n",
    "        resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n",
    "        model=channel.Channel(type=standard_artifacts.Model),\n",
    "        model_blessing=channel.Channel(type=standard_artifacts.ModelBlessing))\n",
    "\n",
    "    # Set the TFMA config for Model Evaluation and Validation.\n",
    "    eval_config = tfma.EvalConfig(\n",
    "       model_specs=[tfma.ModelSpec(label_key='label')],\n",
    "       slicing_specs=[tfma.SlicingSpec()],\n",
    "       metrics_specs=[\n",
    "           tfma.MetricsSpec(metrics=[\n",
    "              tfma.MetricConfig(\n",
    "                  class_name='SparseCategoricalAccuracy',\n",
    "                  threshold=tfma.MetricThreshold(\n",
    "                      # Accept models only if SparseCategoricalAccuracy > 0.8\n",
    "                      value_threshold=tfma.GenericValueThreshold(\n",
    "                          lower_bound={'value': 0.8}),\n",
    "                      # TODO: modify this\n",
    "                      change_threshold=tfma.GenericChangeThreshold(\n",
    "                          direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
    "                          absolute={'value': -1e-2})))\n",
    "          ])\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    evaluator = Evaluator(\n",
    "        examples=example_gen.outputs['examples'],\n",
    "        model=trainer.outputs['model'],\n",
    "        baseline_model=model_resolver.outputs['model'],\n",
    "        # Change threshold will be ignored if there is no baseline (first run).\n",
    "        eval_config=eval_config)\n",
    "\n",
    "    pusher = Pusher(\n",
    "        model=trainer.outputs['model'],\n",
    "        #model_blessing=evaluator.outputs['blessing'],\n",
    "        push_destination=pusher_pb2.PushDestination(\n",
    "            filesystem=pusher_pb2.PushDestination.Filesystem(\n",
    "                base_directory=SERVING_MODEL_DIR)))\n",
    "\n",
    "    components=[\n",
    "        example_gen, statistics_gen, schema_gen, example_validator, \n",
    "        transform, trainer, pusher\n",
    "    ]\n",
    "\n",
    "    return tfx_pipeline.Pipeline(\n",
    "        pipeline_name=pipeline_name,\n",
    "        pipeline_root=PIPELINE_ROOT,\n",
    "        components=components,\n",
    "        metadata_connection_config=metadata_connection_config\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-product",
   "metadata": {},
   "source": [
    "### Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "patient-engine",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:From /opt/conda/lib/python3.7/site-packages/tfx/components/common_nodes/resolver_node.py:74: The name tfx.components.common_nodes.resolver_node.ResolverNode is deprecated. Please use tfx.dsl.components.common.resolver.ResolverNode instead.\n",
      "WARNING:absl:`instance_name` is deprecated, please set the node id directly using `with_id()` or the `.id` setter.\n",
      "WARNING:absl:`instance_name` is deprecated, please set the node id directly using `with_id()` or the `.id` setter.\n"
     ]
    }
   ],
   "source": [
    "mypipeline = create_tfx_pipeline(\n",
    "          pipeline_name=PIPELINE_NAME,\n",
    "          input_dir=RAW_DATA,\n",
    "          metadata_connection_config=metadata.sqlite_metadata_connection_config(METADATA_PATH)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-blake",
   "metadata": {},
   "source": [
    "#### Run Pipeline in Local environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "LocalDagRunner().run(mypipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-sunrise",
   "metadata": {},
   "source": [
    "### Execute Pi in AI Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-trade",
   "metadata": {},
   "source": [
    "Install Kubeflow Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install kfp --upgrade --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-chapel",
   "metadata": {},
   "source": [
    "Copy transform and trainer functions to cloud storage to be accessable via AI Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "economic-employee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://transform.py [Content-Type=text/x-python]...\n",
      "/ [1 files][  2.8 KiB/  2.8 KiB]                                                \n",
      "Operation completed over 1 objects/2.8 KiB.                                      \n",
      "Copying file://trainer.py [Content-Type=text/x-python]...\n",
      "/ [1 files][  5.2 KiB/  5.2 KiB]                                                \n",
      "Operation completed over 1 objects/5.2 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp transform.py gs://crazy-hippo-01/tfx/binary_classification\n",
    "!gsutil cp trainer.py gs://crazy-hippo-01/tfx/binary_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-apple",
   "metadata": {},
   "source": [
    "Set AI Platform environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unknown-ambassador",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID         = 'crazy-hippo-01'\n",
    "REGION             = 'us-central1'\n",
    "API_KEY            = ''\n",
    "PIPELINE_NAME      = 'earnings'\n",
    "PIPELINE_ROOT      = 'gs://crazy-hippo-01/tfx/binary_classification/pipeline'\n",
    "TRANSFORM_FILE     = 'gs://crazy-hippo-01/tfx/binary_classification/transform.py'\n",
    "TRAINER_FILE       = 'gs://crazy-hippo-01/tfx/binary_classification/trainer.py'\n",
    "RAW_DATA           = \"gs://crazy-hippo-01/tfx/binary_classification/raw/\"\n",
    "SERVING_MODEL_DIR  = 'gs://crazy-hippo-01/tfx/binary_classification/serving_model/'\n",
    "METADATA_PATH      = os.path.join('.', 'tfx_metadata', PIPELINE_NAME, 'metadata.db')\n",
    "API_KEY = 'AIzaSyBZQOYPxdfgGzmc5qMr6-LMFK8RHH9RSMs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-distribution",
   "metadata": {},
   "source": [
    "Create pipeline JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-scholar",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = kubeflow_v2_dag_runner.KubeflowV2DagRunnerConfig(\n",
    "    project_id=PROJECT_ID,\n",
    "    display_name=PIPELINE_NAME)\n",
    "\n",
    "runner = kubeflow_v2_dag_runner.KubeflowV2DagRunner(\n",
    "    config=config,\n",
    "    output_filename='pipeline01.json')\n",
    "\n",
    "runner.run(pipeline=mypipeline, write_out=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-irrigation",
   "metadata": {},
   "source": [
    "Import AI Platform Client set up variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "informational-soccer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earnings1614519655\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from aiplatform.pipelines import client\n",
    "\n",
    "api_client = client.Client(project_id=PROJECT_ID, region=REGION, api_key=API_KEY)\n",
    "DISPLAY_NAME = 'earnings{}'.format(str(int(time.time())))\n",
    "print(DISPLAY_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-forestry",
   "metadata": {},
   "source": [
    "Create run from job spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "chief-teaching",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "See the Pipeline job <a href=\"https://console.cloud.google.com/ai/platform/pipelines/runs/earnings1614519655?e=CaipPipelinesAlphaLaunch::CaipPipelinesAlphaEnabled,BackendzOverridingLaunch::BackendzOverridingEnabled,CloudAiLaunch::CloudAiEnabled&project=crazy-hippo-01\" target=\"_blank\" >here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = api_client.create_run_from_job_spec(\n",
    "          job_spec_path='pipeline01.json',\n",
    "          name = DISPLAY_NAME\n",
    "          )"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.mnightly-2021-01-20-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:mnightly-2021-01-20-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
