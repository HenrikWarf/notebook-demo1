{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "above-register",
   "metadata": {},
   "source": [
    "# Productionazing Machine Learning with Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-selection",
   "metadata": {},
   "source": [
    "### Set up project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "adjustable-worse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID:  crazy-hippo-01\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "PROJECT_ID = \"crazy-hippo-01\"\n",
    "\n",
    "# Get your Google Cloud project ID from gcloud\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID: \", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-basics",
   "metadata": {},
   "source": [
    "### Define Current Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "breathing-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp:  20210602062530\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "print('Timestamp: ', TIMESTAMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-lighter",
   "metadata": {},
   "source": [
    "### Create storage bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "anticipated-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"gs://crazy-vertex-ai-pipelines\"\n",
    "REGION = \"us-central1\" \n",
    "ML_PROJECT_NAME = \"earnings_classifier\"\n",
    "USER = \"crazy-hippo\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-still",
   "metadata": {},
   "source": [
    "If you need to create the Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "moved-tanzania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://crazy-vertex-ai-pipelines/...\n"
     ]
    }
   ],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "useful-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-revision",
   "metadata": {},
   "source": [
    "### Import Libraries and define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "dress-reserve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/usr/local/cuda/bin:/opt/conda/bin:/opt/conda/condabin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/home/jupyter/.local/bin:/home/jupyter/.local/bin:/home/jupyter/.local/bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gs://crazy-vertex-ai-pipelines/earnings_classifier/crazy-hippo'"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin\n",
    "\n",
    "PIPELINE_ROOT = \"{}/{}/{}\".format(BUCKET_NAME, ML_PROJECT_NAME, USER)\n",
    "\n",
    "PIPELINE_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "hollywood-qualification",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import NamedTuple\n",
    "\n",
    "from kfp import dsl\n",
    "from kfp.v2 import compiler\n",
    "from kfp.v2.dsl import component\n",
    "from kfp.v2.google.client import AIPlatformClient\n",
    "\n",
    "from kfp.v2.dsl import (\n",
    "    Input,\n",
    "    Output,\n",
    "    Artifact,\n",
    "    Model,\n",
    "    Dataset,\n",
    "    Metrics,\n",
    "    InputPath\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-plane",
   "metadata": {},
   "source": [
    "### Define Pipeline Comnponents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-hometown",
   "metadata": {},
   "source": [
    "#### Pipeline Step 1 - Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "caring-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(output_component_file='read_transform_data.yaml',\n",
    "          base_image='python:3.9',\n",
    "          packages_to_install=['pandas', \n",
    "                             'google-cloud-bigquery', \n",
    "                             'pyarrow' , \n",
    "                             'gcsfs',\n",
    "                             'numpy'\n",
    "                              ])\n",
    "def extract_data(\n",
    "        INPUT_DATA : str,\n",
    "        DATASET_VERSION : int,\n",
    "        DATASET : Output[Dataset],\n",
    "        pipeline_metrics: Output[Metrics]) -> NamedTuple(\n",
    "          'ComponentOutputs',\n",
    "          [\n",
    "              ('dataset_name', str),\n",
    "              ('dataset_version', int),\n",
    "              ('num_of_examples', int),\n",
    "              ('categorical_col', int),\n",
    "              ('numeric_col', int)\n",
    "          ]\n",
    "    ):\n",
    "    \n",
    "    #Import libraries\n",
    "    import pandas as pd\n",
    "    import time\n",
    "    import numpy\n",
    "    from google.cloud.bigquery import Client, QueryJobConfig\n",
    "    \n",
    "    \n",
    "    #Initiate BigQuery Client\n",
    "    client = Client(project='crazy-hippo-01')\n",
    "    \n",
    "    query = \"\"\"SELECT age, workclass, occupation, education_num, marital_status, capital_gain, income_bracket\n",
    "    FROM `crazy-hippo-01.census_data_us.census_raw` \n",
    "    LIMIT 20000\n",
    "    \"\"\"\n",
    "    \n",
    "    #Run Query\n",
    "    job = client.query(query)\n",
    "    df = job.to_dataframe()\n",
    "    \n",
    "    #Set and calculate Dataset Metadata\n",
    "    dataset_name = INPUT_DATA\n",
    "    dataset_version = DATASET_VERSION\n",
    "    num_of_examples = len(df)\n",
    "    \n",
    "    #Data Types\n",
    "    categorical_col = 0\n",
    "    numeric_col = 0\n",
    "    for col in df.columns : \n",
    "        print(type(df[col][0]))\n",
    "        if type(df[col][0]) == str :  \n",
    "            categorical_col += 1\n",
    "        elif type(df[col][0]) == numpy.int64 :\n",
    "            numeric_col += 1\n",
    "    \n",
    "    #Write data to GCS \n",
    "    df.to_csv(DATASET.path, index=False, header=True)\n",
    "    \n",
    "    # Log Metrics\n",
    "    pipeline_metrics.log_metric('dataset_name', dataset_name)\n",
    "    pipeline_metrics.log_metric('dataset_version', dataset_version)\n",
    "    pipeline_metrics.log_metric('num_of_examples', num_of_examples)\n",
    "    pipeline_metrics.log_metric('categorical_col', categorical_col)\n",
    "    pipeline_metrics.log_metric('numeric_col', numeric_col)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    from collections import namedtuple\n",
    "    \n",
    "    component_outputs = namedtuple('ComponentOutputs',\n",
    "        ['dataset_name', \n",
    "         'dataset_version', \n",
    "         'num_of_examples', \n",
    "         'categorical_col', \n",
    "         'numeric_col'])\n",
    "        \n",
    "    return component_outputs(dataset_name, \n",
    "                             dataset_version, \n",
    "                             num_of_examples, \n",
    "                             categorical_col, \n",
    "                             numeric_col)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-saint",
   "metadata": {},
   "source": [
    "#### Pipeline Step 2 - Transform and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "dangerous-faculty",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(output_component_file='read_transform_data.yaml',\n",
    "          base_image='python:3.9',\n",
    "          packages_to_install=['pandas', \n",
    "                             'google-cloud-bigquery', \n",
    "                             'pyarrow' , \n",
    "                             'gcsfs', \n",
    "                             'sklearn'])\n",
    "def read_transform_data(\n",
    "        DATASET : Input[Dataset],\n",
    "        TRAINING_DATA : Output[Dataset],\n",
    "        TEST_DATA : Output[Dataset],\n",
    "        VALIDATION_DATA : Output[Dataset]\n",
    "    ):\n",
    "    \n",
    "    #Import libraries\n",
    "    import pandas as pd\n",
    "    import time\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from google.cloud.bigquery import Client, QueryJobConfig\n",
    "    \n",
    "    df = pd.read_csv(DATASET.path)\n",
    "    \n",
    "    #Drop null values in dataset\n",
    "    df = df.dropna()\n",
    "    \n",
    "    #Create training, test and validation datasets\n",
    "    train, test = train_test_split(df, test_size=0.20, random_state=42)\n",
    "    train, val = train_test_split(train, test_size=0.20, random_state=42)\n",
    "\n",
    "    #Define Staging Bucket in GCS\n",
    "    #BUCKET = 'gcs://crazy-hippo-01/kubeflow_staging/earnings_model/'\n",
    "    #TRAINING_PATH = BUCKET + 'datasets/training/training{}'.format(str(int(time.time())))  + '.csv'\n",
    "    #TEST_PATH = BUCKET + 'datasets/testing/test{}'.format(str(int(time.time())))  + '.csv'\n",
    "    #VALIDATION_PATH = BUCKET + 'datasets/validation/validation{}'.format(str(int(time.time())))  + '.csv'\n",
    "    \n",
    "    #Define Datasets Names\n",
    "    #TRAINING_DATA.uri = TRAINING_PATH\n",
    "    #TEST_DATA.uri = TEST_PATH\n",
    "    #VALIDATION_DATA.uri = VALIDATION_PATH\n",
    "    \n",
    "    print(TRAINING_DATA.path)\n",
    "    print(TEST_DATA.path)\n",
    "    print(VALIDATION_DATA.path)\n",
    "\n",
    "    #Write data to GCS Storage\n",
    "    train.to_csv(TRAINING_DATA.path, index=False, header=True)\n",
    "    test.to_csv(TEST_DATA.path, index=False, header=True)\n",
    "    val.to_csv(VALIDATION_DATA.path, index=False, header=True)\n",
    "\n",
    "    #Define outputs with namedtuple\n",
    "    #from collections import namedtuple\n",
    "    \n",
    "    #return_values = namedtuple(\n",
    "    #  'ComponentOutputs',\n",
    "    #    ['training_data', 'test_data', 'validation_data'])\n",
    "        \n",
    "    #return TRAINING_DATA, TEST_DATA), VALIDATION_DATA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-rating",
   "metadata": {},
   "source": [
    "#### Pipeline Step 3 - Train and Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "helpful-brighton",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(output_component_file='train_model.yaml',\n",
    "          base_image='python:3.9',\n",
    "          packages_to_install=['pandas', \n",
    "                             'pyarrow' , \n",
    "                             'gcsfs' , \n",
    "                             'google-cloud-bigquery-storage',\n",
    "                             'tensorflow'])\n",
    "def train_model(TRAINING_DATA: Input[Dataset], \n",
    "                TEST_DATA: Input[Dataset], \n",
    "                VALIDATION_DATA: Input[Dataset],\n",
    "                MODEL: Output[Model]\n",
    "               ):\n",
    "    \n",
    "    \n",
    "    import pandas as pd\n",
    "    import time\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    from tensorflow.keras.layers.experimental import preprocessing\n",
    "    \n",
    "    #VARIABLES AND TRAINING PARAMETERS\n",
    "    TRAIN_DATA = pd.read_csv(TRAINING_DATA.path)\n",
    "    TEST_DATA = pd.read_csv(TEST_DATA.path)\n",
    "    VAL_DATA = pd.read_csv(VALIDATION_DATA.path)\n",
    "    \n",
    "    BATCH_SIZE = 32\n",
    "    \n",
    "    print(tf.__version__)\n",
    "    \n",
    "    print(MODEL.path)\n",
    "\n",
    "    #TENSORFLOW DATASET FUNCTION\n",
    "    def helperfunc_create_dataset(dataframe, shuffle=True, batch_size=5):\n",
    "        dataframe = dataframe.copy()\n",
    "        labels = dataframe.pop('income_bracket')\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "        ds = ds.batch(batch_size)\n",
    "        ds = ds.prefetch(batch_size)\n",
    "        return ds\n",
    "    \n",
    "    #NORMALIZATION FUNCTION\n",
    "    def helperfunc_get_normalization_layer(name, dataset):\n",
    "        # Create a Normalization layer for our feature.\n",
    "        normalizer = preprocessing.Normalization()\n",
    "\n",
    "        # Prepare a Dataset that only yields our feature.\n",
    "        feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "        # Learn the statistics of the data.\n",
    "        normalizer.adapt(feature_ds)\n",
    "\n",
    "        return normalizer\n",
    "    \n",
    "    #CATEGORY ENCODING FUNCTION\n",
    "    def helperfunc_get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "        # Create a StringLookup layer which will turn strings into integer indices\n",
    "        if dtype == 'string':\n",
    "            index = preprocessing.StringLookup(max_tokens=max_tokens)\n",
    "        else:\n",
    "            index = preprocessing.IntegerLookup(max_values=max_tokens)\n",
    "\n",
    "        # Prepare a Dataset that only yields our feature\n",
    "        feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "        # Learn the set of possible values and assign them a fixed integer index.\n",
    "        index.adapt(feature_ds)\n",
    "\n",
    "        # Create a Discretization for our integer indices.\n",
    "        encoder = preprocessing.CategoryEncoding(max_tokens=index.vocab_size())\n",
    "\n",
    "        # Prepare a Dataset that only yields our feature.\n",
    "        feature_ds = feature_ds.map(index)\n",
    "\n",
    "        # Learn the space of possible indices.\n",
    "        encoder.adapt(feature_ds)\n",
    "\n",
    "        # Apply one-hot encoding to our indices. The lambda function captures the\n",
    "        # layer so we can use them, or include them in the functional model later.\n",
    "        return lambda feature: encoder(index(feature))\n",
    "    \n",
    "    #CREATE TENSORFLOW DATASETS\n",
    "    TRAIN_DS = helperfunc_create_dataset(TRAIN_DATA, batch_size=BATCH_SIZE)\n",
    "    VALIDATION_DS = helperfunc_create_dataset(VAL_DATA, shuffle=False, batch_size=BATCH_SIZE)\n",
    "    TESTING_DS = helperfunc_create_dataset(TEST_DATA, shuffle=False, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    #CREATE PREPROCESSING LAYERS\n",
    "    ALL_INPUTS = []\n",
    "    ENCODED_FEATURES = []\n",
    "\n",
    "    NUMERICAL = ['age' , 'capital_gain']\n",
    "    CATEGORICAL_INT_COLS = ['education_num']\n",
    "    CATEGORICAL_STRING_COLS = ['occupation', \n",
    "                               'workclass', \n",
    "                               'marital_status']\n",
    "    TARGET = ['income_bracket']\n",
    "    \n",
    "    # Numeric features.\n",
    "    for header in NUMERICAL:\n",
    "        numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "        normalization_layer = helperfunc_get_normalization_layer(header, TRAIN_DS)\n",
    "        encoded_numeric_col = normalization_layer(numeric_col)\n",
    "        ALL_INPUTS.append(numeric_col)\n",
    "        ENCODED_FEATURES.append(encoded_numeric_col)\n",
    "        \n",
    "    # Categorical features encoded as integers.\n",
    "    for header in CATEGORICAL_INT_COLS:\n",
    "        categorical_int_col = tf.keras.Input(shape=(1,), name=header, dtype='int64')\n",
    "        encoding_layer = helperfunc_get_category_encoding_layer(header, TRAIN_DS, dtype='int64', max_tokens=5)\n",
    "        encoded_categorical_int_col = encoding_layer(categorical_int_col)\n",
    "        ALL_INPUTS.append(categorical_int_col)\n",
    "        ENCODED_FEATURES.append(encoded_categorical_int_col)\n",
    "    \n",
    "    # Categorical features encoded as string.\n",
    "    for header in CATEGORICAL_STRING_COLS:\n",
    "        categorical_string_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
    "        encoding_layer = helperfunc_get_category_encoding_layer(header, TRAIN_DS, dtype='string', max_tokens=5)\n",
    "        encoded_categorical_string_col = encoding_layer(categorical_string_col)\n",
    "        ALL_INPUTS.append(categorical_string_col)\n",
    "        ENCODED_FEATURES.append(encoded_categorical_string_col)\n",
    "    \n",
    "        \n",
    "    #CREATE and COMPILE MODEL\n",
    "    all_features = tf.keras.layers.concatenate(ENCODED_FEATURES)\n",
    "    x = tf.keras.layers.Dense(32, activation=\"relu\")(all_features)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    output = tf.keras.layers.Dense(1)(x)\n",
    "    model = tf.keras.Model(ALL_INPUTS, output)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    #TRAIN MODEL\n",
    "    history = model.fit(TRAIN_DS, epochs=10, validation_data=VALIDATION_DS)\n",
    "    \n",
    "    \n",
    "    #Define Bucket in GCS for Model Storage\n",
    "    BUCKET = 'gs://crazy-hippo-01/kubeflow_staging/earnings_model/models/'\n",
    "    \n",
    "    #Define MODEL PATH \n",
    "    MODEL_PATH = BUCKET + 'earnings_model{}'.format(str(int(time.time())))\n",
    "    \n",
    "    MODEL.uri = MODEL_PATH \n",
    "    \n",
    "    \n",
    "    #Save model to Artifact Store for Project\n",
    "    model.save(MODEL.path)\n",
    "    \n",
    "    print('Model saved to: ' + MODEL.path)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-chest",
   "metadata": {},
   "source": [
    "#### Pipeline Step 4 - Evaluate Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "suitable-webcam",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(output_component_file='evaluate_model.yaml',\n",
    "          base_image='python:3.9',\n",
    "          packages_to_install=['pandas',\n",
    "                         'google-cloud-bigquery',\n",
    "                         'pyarrow', \n",
    "                         'gcsfs',\n",
    "                         'tensorflow',\n",
    "                         'google-cloud-aiplatform'])\n",
    "def evaluate_validate_model(\n",
    "                            MODEL : Input[Model], \n",
    "                            TEST_DATA: Input[Dataset], \n",
    "                            num_of_examples: int,\n",
    "                            categorical_col: int,\n",
    "                            numeric_col: int,\n",
    "                            pipeline:str, \n",
    "                            framework:str,\n",
    "                            input_path:str,\n",
    "                            dataset_version:int,\n",
    "                            pipeline_metrics: Output[Metrics]) -> NamedTuple(\n",
    "      'ComponentOutputs',\n",
    "      [\n",
    "          ('accuracy', float),\n",
    "          ('loss', float),\n",
    "      ]):\n",
    "    \n",
    "    import pandas as pd\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    \n",
    "    #HELPER FUNCTION - TENSORFLOW DATASET FUNCTION\n",
    "    def helperfunc_create_dataset(dataframe, shuffle=True, batch_size=5):\n",
    "        dataframe = dataframe.copy()\n",
    "        labels = dataframe.pop('income_bracket')\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "        ds = ds.batch(batch_size)\n",
    "        ds = ds.prefetch(batch_size)\n",
    "        return ds\n",
    "    \n",
    "    #LOAD TRAINED MODEL FROM ARTIFACT STORE\n",
    "    reloaded_model = tf.keras.models.load_model(MODEL.path)\n",
    "    \n",
    "    #READ TESTING DATASET\n",
    "    TESTING_DATA = pd.read_csv(TEST_DATA.path)\n",
    "\n",
    "    #SET BATCG SIZE\n",
    "    BATCH_SIZE = 32\n",
    "    \n",
    "    #CALL HELPER FUNCTION TO CREATE TENSORFLOW DATASET\n",
    "    TESTING_DS = helperfunc_create_dataset(TESTING_DATA, shuffle=False, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    #EVALUATE MODEL WITH TEST DATA\n",
    "    loss, accuracy = reloaded_model.evaluate(TESTING_DS)\n",
    "    \n",
    "    accuracy = float(accuracy)\n",
    "    loss = float(loss)\n",
    "    \n",
    "    #PRINT ACCURACY METRIC\n",
    "    print(\"Accuracy\", accuracy)\n",
    "    print(\"Loss\", loss)\n",
    "    \n",
    "    \n",
    "    from tensorflow.python.lib.io import file_io    \n",
    "    \n",
    "    #Write Metrics to BigQuery Table for Validation and possible promotion to Deployment\n",
    "    from google.cloud.bigquery import Client, QueryJobConfig\n",
    "    \n",
    "    #Initiate BigQuery Client\n",
    "    client = Client(project='crazy-hippo-01')\n",
    "    \n",
    "    print('Sending Metrics into BigQuery')\n",
    "    \n",
    "    #Define DML Query to Insert Metrics into BugQuery\n",
    "    query = \"\"\"INSERT `crazy-hippo-01.census_data_us.model_metrics_history` (model_name, pipeline, framework, accuracy, loss)\n",
    "    VALUES (\"{}\", \"{}\", \"{}\", {}, {})  \n",
    "    \"\"\".format(MODEL.path, pipeline, framework, accuracy, loss)\n",
    "    \n",
    "    #Run Query\n",
    "    job = client.query(query)\n",
    "    \n",
    "    print('Metrics sent to BigQuery!')\n",
    "    \n",
    "    # Export two metrics\n",
    "    pipeline_metrics.log_metric('accuracy', accuracy)\n",
    "    pipeline_metrics.log_metric('loss', loss)\n",
    "\n",
    "    from collections import namedtuple\n",
    "    \n",
    "    component_outputs = namedtuple('ComponentOutputs',\n",
    "        ['accuracy', 'loss'])\n",
    "    \n",
    "    \n",
    "    from datetime import datetime\n",
    "    \n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    MY_PROJECT = 'crazy-hippo-01'\n",
    "    REGION = 'us-central1'\n",
    "    EXPERIMENT_NAME = 'earnings-classifier-ver1'\n",
    "    RUN_NAME = \"tensorflow-dl-model-\" + TIMESTAMP\n",
    "    \n",
    "    \n",
    "    #Store Experiment Metrics in Vertex AI\n",
    "    from google.cloud import aiplatform\n",
    "\n",
    "    aiplatform.init(project=MY_PROJECT, location=REGION, experiment=EXPERIMENT_NAME)\n",
    "    aiplatform.start_run(run=RUN_NAME)\n",
    "    \n",
    "    PARAMETERS = {\n",
    "        #\"Model\" : MODEL,\n",
    "        #\"Pipeline\" : pipeline,\n",
    "        #\"Dataset\" : input_path,\n",
    "        \"Dataset Version\" : dataset_version\n",
    "    }\n",
    "    \n",
    "    aiplatform.log_params(PARAMETERS)\n",
    "    \n",
    "    METRICS = {\n",
    "        'Num_of_examples': num_of_examples,\n",
    "        'Categorical_col': categorical_col,\n",
    "        'Numeric_col': numeric_col,\n",
    "        \"Accuracy\": accuracy, \n",
    "        \"Loss\": loss\n",
    "    }\n",
    "    \n",
    "    aiplatform.log_metrics(METRICS)\n",
    "    \n",
    "    from collections import namedtuple\n",
    "    \n",
    "    component_outputs = namedtuple('ComponentOutputs', \n",
    "                                   ['accuracy', 'loss'])\n",
    "    \n",
    "        \n",
    "    return component_outputs(accuracy, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-latest",
   "metadata": {},
   "source": [
    "### Define Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "chief-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "  name='binaryclassmodel6',\n",
    "  description='Binary Classification Model with Tensorflow Deep Learning and Connected Pre-processing Layers'\n",
    ")\n",
    "def binary_classifier_earnings_v6(\n",
    "    pipeline: str = 'Tensorflow DL Version 6',\n",
    "    framework: str = 'Tensorflow',\n",
    "    input_path: str = 'crazy-hippo-01.census_data_us.census_raw',\n",
    "    dataset_version: int = 3\n",
    "    ):\n",
    "    \n",
    "    first_step = extract_data(input_path,\n",
    "                              dataset_version)\n",
    "   \n",
    "    second_step = read_transform_data(first_step.outputs['DATASET'])\n",
    "    #first_step.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "\n",
    "   \n",
    "    third_step = train_model(second_step.outputs['TRAINING_DATA'], \n",
    "                             second_step.outputs['TEST_DATA'], \n",
    "                             second_step.outputs['VALIDATION_DATA'])\n",
    "    #second_step.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    \n",
    "\n",
    "    fourth_step = evaluate_validate_model(third_step.outputs['MODEL'], \n",
    "                                          second_step.outputs['TEST_DATA'],\n",
    "                                          first_step.outputs['num_of_examples'],\n",
    "                                          first_step.outputs['categorical_col'],\n",
    "                                          first_step.outputs['numeric_col'],\n",
    "                                          pipeline, \n",
    "                                          framework, \n",
    "                                          input_path, \n",
    "                                          dataset_version)\n",
    "    #third_step.execution_options.caching_strategy.max_cache_staleness = \"P0D\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-father",
   "metadata": {},
   "source": [
    "### Compile and run Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-conflict",
   "metadata": {},
   "source": [
    "Compile pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "outer-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2 import compiler  \n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=binary_classifier_earnings_v6, package_path=\"earnings_pipeline_ver6.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-european",
   "metadata": {},
   "source": [
    "Instantiate the API client object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "enclosed-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2.google.client import AIPlatformClient  # noqa: F811\n",
    "\n",
    "api_client = AIPlatformClient(\n",
    "    project_id=PROJECT_ID,\n",
    "    region=REGION,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-darkness",
   "metadata": {},
   "source": [
    "Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "pleasant-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT = 'pipelines-vertex-ai@crazy-hippo-01.iam.gserviceaccount.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "brutal-activity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/binaryclassmodel6-20210602065758?project=crazy-hippo-01\" target=\"_blank\" >here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = api_client.create_run_from_job_spec(\n",
    "    job_spec_path=\"earnings_pipeline_ver6.json\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    service_account=SERVICE_ACCOUNT \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-february",
   "metadata": {},
   "source": [
    "Alternate Test SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "abstract-learning",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT = 'edit-rights@crazy-hippo-01.iam.gserviceaccount.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-visibility",
   "metadata": {},
   "source": [
    "#### Looking at Experiment Metrics and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "fabulous-fifty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>param.Dataset Version</th>\n",
       "      <th>metric.Accuracy</th>\n",
       "      <th>metric.Loss</th>\n",
       "      <th>metric.Numeric_col</th>\n",
       "      <th>metric.Num_of_examples</th>\n",
       "      <th>metric.Categorical_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>earnings-classifier-ver1</td>\n",
       "      <td>tensorflow-dl-model-20210602072024</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.780287</td>\n",
       "      <td>0.422863</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>earnings-classifier-ver1</td>\n",
       "      <td>tensorflow-dl-model-20210602065847</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.714663</td>\n",
       "      <td>0.554881</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>earnings-classifier-ver1</td>\n",
       "      <td>tensorflow-dl-model-20210602065832</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.780287</td>\n",
       "      <td>0.421879</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>earnings-classifier-ver1</td>\n",
       "      <td>tensorflow-dl-model-20210602065736</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.704569</td>\n",
       "      <td>0.542066</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>earnings-classifier-ver1</td>\n",
       "      <td>tensorflow-dl-model-20210602064751</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.707679</td>\n",
       "      <td>0.549996</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>earnings-classifier-ver1</td>\n",
       "      <td>tensorflow-dl-model-20210528135115</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.663043</td>\n",
       "      <td>0.598730</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>earnings-classifier-ver1</td>\n",
       "      <td>tensorflow-dl-model-20210528135009</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.702880</td>\n",
       "      <td>0.551616</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>earnings-classifier-ver1</td>\n",
       "      <td>tensorflow-dl-model-20210528132112</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.784006</td>\n",
       "      <td>0.422313</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>earnings-classifier-ver1</td>\n",
       "      <td>tensorflow-dl-model-20210528132044</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.714590</td>\n",
       "      <td>0.552858</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>earnings-classifier-ver1</td>\n",
       "      <td>tensorflow-dl-model-20210528132043</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.809443</td>\n",
       "      <td>0.377089</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>earnings-classifier-ver1</td>\n",
       "      <td>tensorflow-dl-model-20210528131942</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.721113</td>\n",
       "      <td>0.532246</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>earnings-classifier-ver1</td>\n",
       "      <td>tensorflow-dl-model-20210528130607</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.834310</td>\n",
       "      <td>0.351374</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32561.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>earnings-classifier-ver1</td>\n",
       "      <td>tensorflow-dl-model-20210528121412</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.834798</td>\n",
       "      <td>0.351636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>earnings-classifier-ver1</td>\n",
       "      <td>tensorflow-dl-model-20210528120533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             experiment_name                            run_name  \\\n",
       "0   earnings-classifier-ver1  tensorflow-dl-model-20210602072024   \n",
       "1   earnings-classifier-ver1  tensorflow-dl-model-20210602065847   \n",
       "2   earnings-classifier-ver1  tensorflow-dl-model-20210602065832   \n",
       "3   earnings-classifier-ver1  tensorflow-dl-model-20210602065736   \n",
       "4   earnings-classifier-ver1  tensorflow-dl-model-20210602064751   \n",
       "5   earnings-classifier-ver1  tensorflow-dl-model-20210528135115   \n",
       "6   earnings-classifier-ver1  tensorflow-dl-model-20210528135009   \n",
       "7   earnings-classifier-ver1  tensorflow-dl-model-20210528132112   \n",
       "8   earnings-classifier-ver1  tensorflow-dl-model-20210528132044   \n",
       "9   earnings-classifier-ver1  tensorflow-dl-model-20210528132043   \n",
       "10  earnings-classifier-ver1  tensorflow-dl-model-20210528131942   \n",
       "11  earnings-classifier-ver1  tensorflow-dl-model-20210528130607   \n",
       "12  earnings-classifier-ver1  tensorflow-dl-model-20210528121412   \n",
       "13  earnings-classifier-ver1  tensorflow-dl-model-20210528120533   \n",
       "\n",
       "    param.Dataset Version  metric.Accuracy  metric.Loss  metric.Numeric_col  \\\n",
       "0                     3.0         0.780287     0.422863                 4.0   \n",
       "1                     3.0         0.714663     0.554881                 4.0   \n",
       "2                     3.0         0.780287     0.421879                 4.0   \n",
       "3                     3.0         0.704569     0.542066                 4.0   \n",
       "4                     3.0         0.707679     0.549996                 4.0   \n",
       "5                     3.0         0.663043     0.598730                 4.0   \n",
       "6                     3.0         0.702880     0.551616                 4.0   \n",
       "7                     3.0         0.784006     0.422313                 4.0   \n",
       "8                     3.0         0.714590     0.552858                 4.0   \n",
       "9                     3.0         0.809443     0.377089                 4.0   \n",
       "10                    3.0         0.721113     0.532246                 4.0   \n",
       "11                    3.0         0.834310     0.351374                 4.0   \n",
       "12                    3.0         0.834798     0.351636                 NaN   \n",
       "13                    NaN              NaN          NaN                 NaN   \n",
       "\n",
       "    metric.Num_of_examples  metric.Categorical_col  \n",
       "0                  20000.0                     3.0  \n",
       "1                   8000.0                     3.0  \n",
       "2                  20000.0                     3.0  \n",
       "3                  15000.0                     3.0  \n",
       "4                  12000.0                     3.0  \n",
       "5                   1000.0                     3.0  \n",
       "6                  12000.0                     3.0  \n",
       "7                  20000.0                     3.0  \n",
       "8                   5000.0                     3.0  \n",
       "9                  25000.0                     3.0  \n",
       "10                 10000.0                     3.0  \n",
       "11                 32561.0                     3.0  \n",
       "12                     NaN                     NaN  \n",
       "13                     NaN                     NaN  "
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "aiplatform.init(project='crazy-hippo-01', \n",
    "                location=REGION, \n",
    "                experiment='earnings-classifier-ver1')\n",
    "\n",
    "experiment_df = aiplatform.get_experiment_df()\n",
    "experiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "joint-belly",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "sb.set_theme(style=\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "premium-swimming",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_df = experiment_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "complimentary-oliver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>param.Dataset Version</th>\n",
       "      <th>metric.Accuracy</th>\n",
       "      <th>metric.Loss</th>\n",
       "      <th>metric.Numeric_col</th>\n",
       "      <th>metric.Num_of_examples</th>\n",
       "      <th>metric.Categorical_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>earnings-classifier-ver1</td>\n",
       "      <td>tensorflow-dl-model-20210602072024</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.780287</td>\n",
       "      <td>0.422863</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>earnings-classifier-ver1</td>\n",
       "      <td>tensorflow-dl-model-20210602065847</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.714663</td>\n",
       "      <td>0.554881</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>earnings-classifier-ver1</td>\n",
       "      <td>tensorflow-dl-model-20210602065832</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.780287</td>\n",
       "      <td>0.421879</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>earnings-classifier-ver1</td>\n",
       "      <td>tensorflow-dl-model-20210602065736</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.704569</td>\n",
       "      <td>0.542066</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>earnings-classifier-ver1</td>\n",
       "      <td>tensorflow-dl-model-20210602064751</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.707679</td>\n",
       "      <td>0.549996</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>earnings-classifier-ver1</td>\n",
       "      <td>tensorflow-dl-model-20210528135115</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.663043</td>\n",
       "      <td>0.598730</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>earnings-classifier-ver1</td>\n",
       "      <td>tensorflow-dl-model-20210528135009</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.702880</td>\n",
       "      <td>0.551616</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>earnings-classifier-ver1</td>\n",
       "      <td>tensorflow-dl-model-20210528132112</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.784006</td>\n",
       "      <td>0.422313</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>earnings-classifier-ver1</td>\n",
       "      <td>tensorflow-dl-model-20210528132044</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.714590</td>\n",
       "      <td>0.552858</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>earnings-classifier-ver1</td>\n",
       "      <td>tensorflow-dl-model-20210528132043</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.809443</td>\n",
       "      <td>0.377089</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>earnings-classifier-ver1</td>\n",
       "      <td>tensorflow-dl-model-20210528131942</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.721113</td>\n",
       "      <td>0.532246</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>earnings-classifier-ver1</td>\n",
       "      <td>tensorflow-dl-model-20210528130607</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.834310</td>\n",
       "      <td>0.351374</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32561.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             experiment_name                            run_name  \\\n",
       "0   earnings-classifier-ver1  tensorflow-dl-model-20210602072024   \n",
       "1   earnings-classifier-ver1  tensorflow-dl-model-20210602065847   \n",
       "2   earnings-classifier-ver1  tensorflow-dl-model-20210602065832   \n",
       "3   earnings-classifier-ver1  tensorflow-dl-model-20210602065736   \n",
       "4   earnings-classifier-ver1  tensorflow-dl-model-20210602064751   \n",
       "5   earnings-classifier-ver1  tensorflow-dl-model-20210528135115   \n",
       "6   earnings-classifier-ver1  tensorflow-dl-model-20210528135009   \n",
       "7   earnings-classifier-ver1  tensorflow-dl-model-20210528132112   \n",
       "8   earnings-classifier-ver1  tensorflow-dl-model-20210528132044   \n",
       "9   earnings-classifier-ver1  tensorflow-dl-model-20210528132043   \n",
       "10  earnings-classifier-ver1  tensorflow-dl-model-20210528131942   \n",
       "11  earnings-classifier-ver1  tensorflow-dl-model-20210528130607   \n",
       "\n",
       "    param.Dataset Version  metric.Accuracy  metric.Loss  metric.Numeric_col  \\\n",
       "0                     3.0         0.780287     0.422863                 4.0   \n",
       "1                     3.0         0.714663     0.554881                 4.0   \n",
       "2                     3.0         0.780287     0.421879                 4.0   \n",
       "3                     3.0         0.704569     0.542066                 4.0   \n",
       "4                     3.0         0.707679     0.549996                 4.0   \n",
       "5                     3.0         0.663043     0.598730                 4.0   \n",
       "6                     3.0         0.702880     0.551616                 4.0   \n",
       "7                     3.0         0.784006     0.422313                 4.0   \n",
       "8                     3.0         0.714590     0.552858                 4.0   \n",
       "9                     3.0         0.809443     0.377089                 4.0   \n",
       "10                    3.0         0.721113     0.532246                 4.0   \n",
       "11                    3.0         0.834310     0.351374                 4.0   \n",
       "\n",
       "    metric.Num_of_examples  metric.Categorical_col  \n",
       "0                  20000.0                     3.0  \n",
       "1                   8000.0                     3.0  \n",
       "2                  20000.0                     3.0  \n",
       "3                  15000.0                     3.0  \n",
       "4                  12000.0                     3.0  \n",
       "5                   1000.0                     3.0  \n",
       "6                  12000.0                     3.0  \n",
       "7                  20000.0                     3.0  \n",
       "8                   5000.0                     3.0  \n",
       "9                  25000.0                     3.0  \n",
       "10                 10000.0                     3.0  \n",
       "11                 32561.0                     3.0  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-vegetable",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "administrative-gallery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAE5CAYAAACj0khxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAhnElEQVR4nO3df1DcV73/8RdLlsRIP67E/FiCmobRSMowesvcznhv7syFWOAKpFE6iSGYmBvjyLRWrLFxem+4t7bOTZuYK260ncFpkETjVxzzqyExP8ZJ/XUdtB1K6a29m6SWZkksFIHQhGX3fP/odW8XWtjALmcXno+ZnQmf99nd91n2kxefz/44acYYIwAAYI3LdgMAAMx2hDEAAJYRxgAAWEYYAwBgGWEMAIBlc2w3AABAqguHw+rq6tK1a9fetv7ud79bOTk5crne/hg4jY82AQAwNVevXtWNGze0dOnSMYEbDof16quvau7cuVq0aNHbXp/T1AAATFFfX58WL178tke+LpdLixcv1l/+8pd3vD5hDADAFIVCIbnd7nesu91ujYyMvGOdMAYAIA7S0tImVZMIYwAArCOMAQCwjDAGACAOxvtw0kQfXJpRnzO+fv26Ojo6tHDhQqWnp9tuBwBgWSgU0p///Gfl5+dr3rx5CbufefPmqaenRwsWLBjz+rAxRj09PePe/4z6nHFbW5uqq6tttwEASDIHDx5UYWFhwm4/GAyqq6tL169ff9v6vHnzlJOT847vuJ5RR8YLFy6U9OaDvmTJEsvdAABs6+7uVnV1dSQfEsXtduvWW2+d9PVnVBj/9dT0kiVLlJOTY7kbAECySPaXLnkDFwAAlhHGAABYRhgDAGAZYQwAgGWEMQAgqfj9faqtPSPHaZDLtVuO06Da2jPy+/tst5YwhDEAIGm0tl5QQcF+NTa2a2BgWMZIAwPDamxsV0HBfrW2XrDdYkIQxgCApOD396mq6qiGhkYUDIajasFgWENDI6qqOjojj5AJYwBAUtizp21MCI8WDIa1d2/bNHU0fQhjAEBSOHCgM6Ywbm7unKaOpg9hDABICoODw3Edl0oIYwBAUsjMzIjruFRCGAMAksLGjSvldo8fS263SzU1K6epo+lDGAMAksL99xfGFMZ1dYlbCtEWwhgAkBRycz1qaanU/PlzxoSy2+3S/Plz1NJSqdxcj50GE4gwBgAkjbKy5Wpv36xt2wrkOBlyuSTHydC2bQVqb9+ssrLltltMiBm1njEAIPXl5nrk862Wz7fadivThiNjAAAsI4wBALCMMAYAwDLCGAAAywhjAAAsI4wBALCMMAYAwDLCGAAAywhjAAAsI4wBALAspjCura1VZWWl7rrrLm3YsEEvvPCCJOnixYtat26dSkpKtG7dOl26dClynUTUAACYkUwM+vv7I/8+ffq0ueuuu4wxxtTU1JjDhw8bY4w5fPiwqampiYxLRG0ir7zyivnwhz9sXnnllZivAwCYuVIlF2I6Mr7lllsi/x4cHFRaWpp6enrU2dmp8vJySVJ5ebk6OzvV29ubkNpo/f396urqirp0d3dP7S8TAAAsiHnVpgcffFC/+tWvZIxRY2OjAoGAFi9erPT0dElSenq6Fi1apEAgIGNM3GtZWVlR/TQ1Ncnn88XlQQAAwKaYw/iRRx6RJB0+fFiPPvqo7rvvvoQ1FYtNmzZp7dq1Udu6u7tVXV1tqSMAACbnptczvuuuu7Rz504tWbJEV65cUSgUUnp6ukKhkK5evSqv1ytjTNxrozmOI8dx4vIgAABg04SvGV+7dk2BQCDy87lz5/Se97xHCxYsUF5eno4fPy5JOn78uPLy8pSVlZWQGgAAM1WaMcaMN+C1115TbW2t3njjDblcLr3nPe/RAw88oNtuu01+v187duxQf3+/HMfRrl27tHz5cklKSG0iXV1dKi4u1tmzZ5WTkzOVxwUAMAOkSi5MGMapJFUedADA9EiVXOAbuAAAsIwwBgDAMsIYAADLCGMAACwjjAEAsIwwBgDAMsIYAADLCGMAACwjjAEAsIwwBgDAMsIYAADLCGMAACwjjAEAsIwwBgDAMsIYAADLCGMAACwjjAEAsIwwBgDAMsIYAADLCGMAACwjjAEAsIwwBgDAMsIYAADLCGMAACwjjAEAsIwwBgDAMsIYAADLCGMAACwjjAEgxfn9faqtPSPHaZDLtVuO06Da2jPy+/tst4YYEcYAkMJaWy+ooGC/GhvbNTAwLGOkgYFhNTa2q6Bgv1pbL9huETGYMIxff/11ff7zn1dJSYkqKip0zz33qLe3V5K0YsUKVVRUaM2aNVqzZo1efPHFyPXOnTun0tJSfeITn9CXv/xlvfHGG1OuAQD+j9/fp6qqoxoaGlEwGI6qBYNhDQ2NqKrqKEfIKWDCME5LS9PWrVt16tQpHTt2TO9///u1e/fuSP3QoUM6cuSIjhw5ohUrVkiSrl27pn/913/V448/rtOnT+vd7363vv/970+pBgCItmdP25gQHi0YDGvv3rZp6giTNWEYezwe3XHHHZGfP/rRj+ry5cvjXuf8+fPKz8/XsmXLJEnr169Xa2vrlGqj9ff3q6urK+rS3d090XQAYMY4cKAzpjBubu6cpo4wWXNuZnA4HNaPfvQjFRUVRbbV1NQoFArpH/7hH3TvvfcqIyNDgUBA2dnZkTHZ2dkKBAKSNOnaaE1NTfL5fDfTPgDMKIODw3EdB3tuKoy/8Y1vaP78+dq4caMk6Re/+IW8Xq8GBwe1fft27du3T3V1dQlpdLRNmzZp7dq1Udu6u7tVXV09LfcPALZlZmZoYGDioM3MzJiGbjAVMb+beteuXXr55Zf1n//5n3K53rya1+uVJGVmZuruu+/WH/7wh8j2t57Kvnz5cmTsZGujOY6jnJycqMuSJUtinQ4ApLyNG1fK7R7/v3G326WampXT1BEmK6Yw/ta3vqWOjg7t27dPGRlv/oX1l7/8RdevX5ckjYyM6NSpU8rLy5MkrVq1Ss8995wuXbok6c03eZWVlU2pBgCIdv/9hTGFcV1d4TR1hMma8DT1Sy+9pCeeeELLli3T+vXrJUk5OTnaunWrdu7cqbS0NI2MjOhjH/uY7rvvPklvHik/9NBD+sIXvqBwOKy8vDw9+OCDU6oBAKLl5nrU0lKpqqqjCgbDUW/mcrtdcrtdammpVG6ux16TiEmaMcbYbiJeurq6VFxcrLNnzyonJ8d2OwAwLfz+Pu3d26bm5k4NDg4rMzNDNTUrVVdXOOuDOFVy4abewAUASD65uR75fKvl86223Qomia/DBADAMsIYAADLCGMAACwjjAEAsIwwBgDAMsIYAADLCGMAACwjjAEAsIwwBgDAMsIYAADLCGMAACwjjAEAsIwwBgDAMsIYAADLCGMAACwjjAEAsIwwBgDAMsIYAADLCGMAACwjjAEAsIwwBgDAMsIYAADLCGMAACwjjAEAsIwwBgDAMsIYAADLCGMAACwjjAHMOOfO/Un5+U8qLW135JKf/6TOnfuT/P4+1daekeM0yOXaLcdpUG3tGfn9fbbbxiw2x3YDABBPDz30a9XX/3rM9uef71Fx8f+T2/3mMUgwGJYkDQwMq7GxXU1NHWppqVRZ2fJp7ReQYjgyfv311/X5z39eJSUlqqio0D333KPe3l5J0rPPPqvKykqVlJRoy5Yt6unpiVwvETUAGM+5c3962yB+q2AwHAnit24bGhpRVdVRjpBhxYRhnJaWpq1bt+rUqVM6duyY3v/+92v37t0Kh8Pavn27du7cqVOnTqmwsFC7d++WpITUAGAiX/rS2SldPxgMa+/etjh1A8RuwjD2eDy64447Ij9/9KMf1eXLl9XR0aG5c+eqsLBQkrR+/XqdPHlSkhJSG62/v19dXV1Rl+7u7kk9CABmhuefn9qZtGAwrObmzjh1A8Tupl4zDofD+tGPfqSioiIFAgFlZ2dHallZWQqHw+rr60tIzePxRPXS1NQkn893s/MFgHENDg7bbgGz0E2F8Te+8Q3Nnz9fGzdu1OnTpxPVU0w2bdqktWvXRm3r7u5WdXW1pY4AzASZmRm2W8AsFHMY79q1Sy+//LIef/xxuVwueb1eXb58OVLv7e2Vy+WSx+NJSG00x3HkOM7NzhfADHbbbQumdKra7XappmZlHDsCYhPT54y/9a1vqaOjQ/v27VNGxpt/Nebn5+v69etqa3vzzQ6HDh1SaWlpwmoAMJGGhuIpXd/tdqmurjBO3QCxm/DI+KWXXtITTzyhZcuWaf369ZKknJwc7du3T48++qjq6+t148YNLV26VI899pgkyeVyxb0GABMpKvqA/v3fPz7ux5tGf874r9vcbpdaWiqVm+tJdJvAGGnGGGO7iXjp6upScXGxzp49q5ycHNvtALDk3Lk/6b77zqqj4/9OWefnL9C3v12sD37Q0d69bWpu7tTg4LAyMzNUU7NSdXWFBPEMlCq5wDdwAZhxioo+oOee+9w71n2+1fL5Vk9jR8D4+G5qAAAsI4wBALCMMAYAwDLCGAAAywhjAAAsI4wBALCMMAYAwDLCGAAAywhjAAAsI4wBALCMMAYAwDLCGAAAywhjAAAsI4wBALCMMAYAwDLCGAAAywhjAAAsI4wBALCMMAYAwDLCGAAAywhjAAAsI4wBALCMMAYAwDLCGAAAywhjAAAsI4wBALCMMAYAwDLCGAnn9/eptvaMHKdBLtduOU6DamvPyO/vs90aACQFwhgJ1dp6QQUF+9XY2K6BgWEZIw0MDKuxsV0FBfvV2nrBdosAYF1MYbxr1y4VFRVpxYoV+uMf/xjZXlRUpNLSUq1Zs0Zr1qzR008/Hak9++yzqqysVElJibZs2aKenp4p15Ba/P4+VVUd1dDQiILBcFQtGAxraGhEVVVHOUIGMOvFFMbFxcU6ePCgli5dOqbW0NCgI0eO6MiRI1q1apUkKRwOa/v27dq5c6dOnTqlwsJC7d69e0o1pJ49e9rGhPBowWBYe/e2TVNHAJCcYgrjwsJCeb3emG+0o6NDc+fOVWFhoSRp/fr1Onny5JRqo/X396urqyvq0t3dHXOPSLwDBzpjCuPm5s5p6ggAktOcqd7AV7/6VRljdPvtt+srX/mKHMdRIBBQdnZ2ZExWVpbC4bD6+vomXfN4PFH329TUJJ/PN9X2kUCDg8NxHQcAM9WUwvjgwYPyer0aHh7WI488ooceemjaTitv2rRJa9eujdrW3d2t6urqabl/TCwzM0MDAxMHbWZmxjR0AwDJa0rvpv7rqeuMjAxt2LBBf/jDHyLbL1++HBnX29srl8slj8cz6dpojuMoJycn6rJkyZKpTAdxtnHjSrnd4z/F3G6XampWTlNHAJCcJh3GQ0NDGhgYkCQZY3TixAnl5eVJkvLz83X9+nW1tb35xpxDhw6ptLR0SjWknvvvL4wpjOvqCqepIwBITjGdpn744Yf185//XK+99po+97nPyePx6PHHH9e9996rUCikcDis3Nxc1dfXS5JcLpceffRR1dfX68aNG1q6dKkee+yxKdWQenJzPWppqVRV1VEFg+GoN3O53S653S61tFQqN9djr0kASAJpxhhju4l46erqUnFxsc6ePaucnBzb7eB/+f192ru3Tc3NnRocHFZmZoZqalaqrq6QIAaQUKmSC1N+NzUwkdxcj3y+1fL5VttuBQCSEl+HCQCAZYQxAACWEcYAAFhGGAMAYBlhDACAZYQxAACWEcYAAFhGGAMAYBlhDACAZYQxAACWEcYAAFhGGAMAYBlhjLjz+/tUW3tGjtMgl2u3HKdBtbVn5Pf3TWocAMx0hDHiqrX1ggoK9quxsV0DA8MyRhoYGFZjY7sKCvartfXCTY0DgNmAMEbc+P19qqo6qqGhEQWD4ahaMBjW0NCIqqqO6ty5P8U0jiNkALMFYYy42bOnbUy4jhYMhvWlL52NadzevW3xbA8AkhZhjLg5cKAzppB9/vmemMY1N3fGsz0ASFqEMeJmcHA4qW8PAJIVYYy4yczMSOrbA4BkRRgjbjZuXCm3e/ynlNvt0m23LYhpXE3Nyni2BwBJizBG3Nx/f2FMIdvQUBzTuLq6wni2BwBJizBG3OTmetTSUqn58+eMCVu326X58+eopaVSRUUfiGlcbq5nGrsHAHsIY8RVWdlytbdv1rZtBXKcDLlckuNkaNu2ArW3b1ZZ2fKbGgcAs0GaMcbYbiJeurq6VFxcrLNnzyonJ8d2OwAAy1IlFzgyBgDAMsIYAADLCGMAACwjjDFrsGQjgGRFGGNWYMlGAMlswjDetWuXioqKtGLFCv3xj3+MbL948aLWrVunkpISrVu3TpcuXUpoDZisWJd25AgZgC0ThnFxcbEOHjyopUuXRm2vr6/Xhg0bdOrUKW3YsEE7d+5MaA2YrFiXdmTJRgC2TBjGhYWF8nq9Udt6enrU2dmp8vJySVJ5ebk6OzvV29ubkNrb6e/vV1dXV9Slu7t78o8EZqxYl3ZkyUYAtsyZzJUCgYAWL16s9PR0SVJ6eroWLVqkQCAgY0zca1lZWWN6aGpqks/nm9SkMbvEuhQjSzYCsGVSYZwMNm3apLVr10Zt6+7uVnV1taWOkKwyMzM0MDBx0LJkIwBbJhXGXq9XV65cUSgUUnp6ukKhkK5evSqv1ytjTNxrb8dxHDmOM6XJY3bYuHGlGhvbxz1VzZKNAGya1EebFixYoLy8PB0/flySdPz4ceXl5SkrKyshNWAqYl3akSUbAdgy4UIRDz/8sH7+85/rtdde03vf+155PB499dRT8vv92rFjh/r7++U4jnbt2qXly99caScRtVikyheCY/q1tl5QVdVRBYPhqCNkt9slt9ullpZKVooCZqBUyQVWbcKs4ff3ae/eNjU3d2pwcFiZmRmqqVmpurpC1k4GZqhUyYWUfQMXcLNycz3y+VbL51ttuxUAiMLXYQIAYBlhDACAZYQxAACWEcYAAFhGGCPlsC4xgJmGMEZKYV1iADMRYYyUwbrEAGYqwhgpg3WJAcxUhDFSBusSA5ipCGOkDNYlBjBTEcZIGbGuN8y6xABSDWGMlLFx48qYlkJkXWIAqYYwRspgXWIAMxVhjJSRm+tRS0ul5s+fMyaU3W6X5s+fo5aWSpZDBJByCGOklLKy5Wpv36xt2wrkOBlyuSTHydC2bQVqb9+ssrLltlsEgJvGesZIOaxLDGCm4cgYAADLCGMAACwjjAEAsIwwBgDAMsIYAADLCGMAACwjjAEAsIwwBgDAMsIYAADLCGMAACwjjAEAsIwwBgDAMsIYKcfv71Nt7Rk5ToNcrt1ynAbV1p6R399nuzUAmJQph3FRUZFKS0u1Zs0arVmzRk8//bQk6dlnn1VlZaVKSkq0ZcsW9fT0RK4z2RrQ2npBBQX71djYroGBYRkjDQwMq7GxXQUF+9XaesF2iwBw0+JyZNzQ0KAjR47oyJEjWrVqlcLhsLZv366dO3fq1KlTKiws1O7duyVp0jXA7+9TVdVRDQ2NKBgMR9WCwbCGhkZUVXWUI2QAKSchp6k7Ojo0d+5cFRYWSpLWr1+vkydPTqkG7NnTNiaERwsGw9q7t22aOgKA+JgTjxv56le/KmOMbr/9dn3lK19RIBBQdnZ2pJ6VlaVwOKy+vr5J1zweT9R99vf3q7+/P2pbd3d3PKaDJHXgQGdMYdzc3Cmfb/U0dQUAUzflMD548KC8Xq+Gh4f1yCOP6KGHHtInPvGJePQ2rqamJvl8voTfD5LH4OBwXMcBQLKYchh7vV5JUkZGhjZs2KAvfvGL+uxnP6vLly9HxvT29srlcsnj8cjr9U6qNtqmTZu0du3aqG3d3d2qrq6e6pSQpDIzMzQwMHHQZmZmTEM3ABA/U3rNeGhoSAMDA5IkY4xOnDihvLw85efn6/r162pre/O1u0OHDqm0tFSSJl0bzXEc5eTkRF2WLFkylekgyW3cuFJu9/hPWbfbpZqaldPUEQDEx5SOjHt6enTvvfcqFAopHA4rNzdX9fX1crlcevTRR1VfX68bN25o6dKleuyxxyRp0jXg/vsL1dTUMe7rxm63S3V1hdPYFQBMXZoxxthuIl66urpUXFyss2fPKicnx3Y7SIDW1guqqjqqYDAcFcput0tut0stLZUqK1tusUMAySRVcoFv4EJKKStbrvb2zdq2rUCOkyGXS3KcDG3bVqD29s0EMYCUFJePNgHTKTfXI59vNR9fAjBjcGQMAIBlhDEAAJYRxgAAWEYYAwBgGWEMAIBlhDEAAJYRxgAAWEYYAwBgGWEMAIBlhDEAAJYRxgAAWEYYAwBgGWEMAIBlhDEAAJYRxgAAWEYYAwBgGWEMAIBlhDEAAJYRxgAAWEYY/y+/v0+1tWfkOA1yuXbLcRpUW3tGfn+f7dYAADMcYSyptfWCCgr2q7GxXQMDwzJGGhgYVmNjuwoK9qu19YLtFgEAM9isD2O/v09VVUc1NDSiYDAcVQsGwxoaGlFV1VGOkAEACTPrw3jPnrYxITxaMBjW3r1t09QRAGC2mfVhfOBAZ0xh3NzcOU0dAQBmm1kfxoODw3EdBwDAzZr1YZyZmRHXcQAA3KxZH8YbN66U2z3+w+B2u1RTs3KaOgIAzDazPozvv78wpjCuqyucpo4AALPNrA/j3FyPWloqNX/+nDGh7Ha7NH/+HLW0VCo312OnQQDAjJeUYXzx4kWtW7dOJSUlWrdunS5dupTQ+ysrW6729s3atq1AjpMhl0tynAxt21ag9vbNKitbntD7BwDMbnNsN/B26uvrtWHDBq1Zs0ZHjhzRzp079YMf/CCh95mb65HPt1o+3+qE3g8AAKMl3ZFxT0+POjs7VV5eLkkqLy9XZ2enent7o8b19/erq6sr6tLd3W2jZQAApiTpjowDgYAWL16s9PR0SVJ6eroWLVqkQCCgrKysyLimpib5fD5bbQIAEDdJF8ax2rRpk9auXRu1rbu7W9XV1ZY6AgBgcpIujL1er65cuaJQKKT09HSFQiFdvXpVXq83apzjOHIcx1KXAADET9KF8YIFC5SXl6fjx49rzZo1On78uPLy8qJOUb+TUCgkSbx2DACQ9H958Nd8SFZpxhhju4nR/H6/duzYof7+fjmOo127dmn58ok/XtTW1sZpagDAGAcPHlRhYfJ+eVNShvFkXb9+XR0dHVq4cGHkDWDJ6K+vbR88eFBLliyx3c6UMZ/kxnyS10yai5Sc8wmFQvrzn/+s/Px8zZs3z3Y77yjpTlNPxbx585L6L5/RlixZopycHNttxA3zSW7MJ3nNpLlIyTefD37wg7ZbmFDSfc4YAIDZhjAGAMAywhgAAMsIYwscx9E999wzYz4nzXySG/NJXjNpLtLMm890mlHvpgYAIBVxZAwAgGWEMQAAlhHGAABYNqO+9MOGixcvaseOHerr65PH49GuXbu0bNmyMeNOnDih733vezLGKC0tTU8++aTe97736Wtf+5pefPHFyLgXX3xR+/btU3Fxsb7zne/ohz/8oRYtWiRJ+pu/+RvV19dbn894PYdCIT388MN6+umnlZaWpm3btunuu++WpHFryTqfffv26cSJE3K5XHK73aqrq9OqVaskSTt27NCvf/1rvfe975UklZaW6otf/GJSz2e859Qbb7yhr3/963r++eeVnp6uBx54QP/4j/+Y1PNJpv0nlrn09PTo61//ugKBgEZGRnTHHXfoX/7lXzRnzpyU3HfGm0+y7TtJz2BKampqzOHDh40xxhw+fNjU1NSMGdPe3m7KysrM1atXjTHG9Pf3m+vXr48Z98ILL5i//du/NTdu3DDGGNPQ0GD+4z/+I4HdjxXLfN5qdM8/+9nPzJYtW0woFDI9PT1m1apV5pVXXpmwlqzzOX/+vBkaGorUbr/9dvPGG28YY4x54IEHTHNzcwK7H2uq8xnvOfWd73zHPPjgg8YYYy5evGg+/vGPm8HBwTh2P9ZU5zNebbr3n1jm8vDDD0d6Gh4eNlVVVeapp54yxqTmvjPefJJt30l2nKaegp6eHnV2dqq8vFySVF5ers7OTvX29kaN279/v7Zs2aKFCxdKkm655RbNnTt3zO21tLSooqJCGRkZiW/+bcQ6n7ca3fOJEyd09913y+VyKSsrS6tXr9bJkycnrCXrfFatWqV3vetdkqQVK1bIGKO+vr6E9TyeeMxnPK2trVq3bp0kadmyZcrPz9f58+fj0/zbiPd8bO4/sc4lLS1N165dUzgc1vDwsILBoBYvXiwpNfed8eaTTPtOKiCMpyAQCGjx4sWRRSnS09O1aNEiBQKBqHF+v1+vvPKKqqurtXbtWn33u9+VGfWJsuHhYR07dkyf/vSno7Y/9dRTqqio0JYtW/TMM88kxXzG6zkQCCg7Ozvys9frjSxhNl4tEeIxn7c6fPiwPvCBD0R9Af6TTz6piooK1dbWyu/3x38SbxGv+bzTc+ry5ctaunRp5OdU+v3Y3n9inUttba0uXryov//7v49cbr/99shtpNq+M9583sr2vpMKCONpEAqF9OKLL+rJJ59Uc3Ozzp8/ryNHjkSNOXPmjLKzs5WXlxfZtn79ep09e1bHjh3TP//zP6u2tlavv/76dLf/jt6u51Q23nx+97vf6dvf/rb27NkT2VZXV6fTp0/r2LFjuvPOO7V169akWjM1FZ9T4xnv95Mqcz158qRWrFihX/7ylzp//rza2toSeoSbaLHMJxX3HRsI4ynwer26cuVK5EkUCoV09epVeb3eqHHZ2dkqLS1VRkaGMjMzVVxcrPb29qgxP/3pT8f8Vb9w4UK53W5J0t/93d/J6/XqpZdesj6f8Xr2er26fPly5OdAIBD5a3i8WiLEYz6S9Mwzz2j79u3at29f1Lraixcvlsv15i501113aWhoKKFHK/GYz3jPqezsbL366quRsany+3mn2nTuP7HO5cCBA6qsrJTL5dItt9yioqIi/dd//VfkNlJt3xlvPlLy7DupgDCeggULFigvL0/Hjx+XJB0/flx5eXnKysqKGldeXq5f/vKXMsYoGAzqt7/9rT7ykY9E6t3d3fr973+vioqKqOtduXIl8u8XXnhBr776qm699Vbr8xmv59LSUv3kJz9ROBxWb2+vzpw5o5KSkglryTqf9vZ21dXVqaGhQbfddltU7a2/n6effloulyvyelkixGM+4z2nSktL9eMf/1iSdOnSJT333HORd78mQjzmM15tOvefWOeSk5MTeR1+eHhYv/nNb/ShD31IUmruO+PNJ5n2nZRg9/1jqe9//ud/TFVVlbnzzjtNVVWV8fv9xhhjtm7datrb240xxoRCIfPNb37TlJaWmn/6p38y3/zmN00oFIrcxne/+13z5S9/ecxtf+1rXzOf/OQnTUVFhfnUpz5lfvGLXyTFfMbreWRkxOzcudMUFxeb4uJic+jQoZhqyTqfT33qU+aOO+4wlZWVkct///d/G2OM2bRpkykvLzcVFRXmM5/5jHnmmWeSfj7jPaeuXbtm7r33XrN69Wpz5513mtOnTyf9fMarTff+E8tcXn75ZbN582ZTXl5uysrKzL/927+ZYDBojEnNfWe8+STbvpPs+G5qAAAs4zQ1AACWEcYAAFhGGAMAYBlhDACAZYQxAACWEcYAAFhGGAMAYNn/B1I1peBICc5oAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(7,5))\n",
    "ax = fig.add_subplot()\n",
    "ax.scatter(ex_df['metric.Accuracy'], ex_df['metric.Num_of_examples'], color='darkblue', s=100)\n",
    "ax.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "supreme-major",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8343098759651184"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_df['metric.Accuracy'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "classified-amino",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ex_df[ex_df['metric.Accuracy'] == ex_df['metric.Accuracy'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "acoustic-variable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>param.Dataset Version</th>\n",
       "      <th>metric.Accuracy</th>\n",
       "      <th>metric.Loss</th>\n",
       "      <th>metric.Numeric_col</th>\n",
       "      <th>metric.Num_of_examples</th>\n",
       "      <th>metric.Categorical_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>earnings-classifier-ver1</td>\n",
       "      <td>tensorflow-dl-model-20210528130607</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.83431</td>\n",
       "      <td>0.351374</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32561.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             experiment_name                            run_name  \\\n",
       "11  earnings-classifier-ver1  tensorflow-dl-model-20210528130607   \n",
       "\n",
       "    param.Dataset Version  metric.Accuracy  metric.Loss  metric.Numeric_col  \\\n",
       "11                    3.0          0.83431     0.351374                 4.0   \n",
       "\n",
       "    metric.Num_of_examples  metric.Categorical_col  \n",
       "11                 32561.0                     3.0  "
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-security",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.mnightly-2021-01-20-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:mnightly-2021-01-20-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
